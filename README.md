# Reproducible Deep Learning
## PhD Course in Data Science, 2021, 3 CFU
[[Official website](https://www.sscardapane.it/teaching/reproducibledl/)]

### Adversarial Attack
On the https://landscape.lfai.foundation/ in the Trusted and Responsible AI (AI Explainability 360 Toolkit), we can find an Adversarial Attack framework. 
In particular, I selected the Adversarial Robustness Toolbox (ART) by IBM, and I applied it to the audionet classificaton model.
In the notebook, I show how to create adversarial examples of audio data with ART. 
In the visualization part, it is possible to compare the original and the perturbed instance.

In the model/ folder, you can find the audionet model already trained.
